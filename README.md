# FlipFlopPrompt

A powerful AI image generation prompt builder with a clean, user-friendly interface. Create, refine, and save prompts for various AI image generation models.

## âœ¨ Features

### **Core Functionality**
- **Multi-Model Support**: Generate prompts optimized for Seedream, Veo, Flux, Wan, and Hailuo
- **LLM Integration**: Uses Ollama for local, free prompt refinement
- **Content Rating System**: PG, NSFW, and custom ratings with appropriate filtering
- **Snippet System**: Quick selection from categorized prompt elements
- **Template System**: Save and load complete prompt configurations
- **Real-time Preview**: See your prompt as you build it

### **User Interface**
- **Clean Design**: Simple, readable interface with clear contrast
- **Intuitive Layout**: Logical field organization and workflow
- **Responsive**: Adapts to different window sizes
- **Accessible**: High contrast colors for readability

### **Data Management**
- **User Data Folders**: Automatic organization of snippets, templates, and preferences
- **Cross-Platform**: Works on Windows, macOS, and Linux
- **Persistent Settings**: Remembers your preferences between sessions
- **Debug System**: Optional detailed logging for troubleshooting

## ğŸš€ Quick Start

### **Prerequisites**
- Python 3.8 or higher
- Ollama (for LLM functionality)

### **Installation**
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/FlipFlopPrompt.git
   cd FlipFlopPrompt
   ```

2. Create a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Start Ollama (if using LLM features):
   ```bash
   ollama serve
   ```

### **Running the Application**
```bash
python main.py --gui
```

## ğŸ“– Usage

### **Basic Workflow**
1. **Select Model**: Choose your target AI image generation model
2. **Set Content Rating**: Select appropriate content rating (affects LLM filtering)
3. **Fill Fields**: Use the form fields to describe your image
4. **Use Snippets**: Click snippet buttons for quick suggestions
5. **Preview**: See your prompt in real-time
6. **Generate**: Click "Generate Prompt" for LLM refinement
7. **Save**: Save your prompt or template for later use

### **Field Descriptions**
- **Style**: Art style (painting, photorealistic, anime, etc.)
- **Setting**: Environment and location
- **Weather**: Atmospheric conditions
- **Date and Time**: Season and time of day
- **Subjects**: Main subjects in the image
- **Pose and Action**: How subjects are positioned/acting
- **Camera**: Camera type and characteristics
- **Framing and Action**: Camera angle and movement
- **Color Grading & Mood**: Visual style and atmosphere
- **Additional Details**: Any extra information

### **Snippets**
- Click the "Snippets" button next to any field
- Browse categories and click items to add/remove them
- Snippets are filtered by content rating
- Supports toggle behavior (click again to remove)

### **Templates**
- **Save Template**: File â†’ Save Template (saves current state)
- **Load Template**: File â†’ Load Template (restores saved state)
- Templates include all field values, settings, and generated prompts
- Stored in user data folder for easy access

## ğŸ—‚ï¸ File Structure

```
FlipFlopPrompt/
â”œâ”€â”€ main.py                 # Application entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ TODO.md                # Development tasks
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ core/              # Core functionality
â”‚   â”‚   â”œâ”€â”€ data_models.py
â”‚   â”‚   â”œâ”€â”€ prompt_engine.py
â”‚   â”‚   â”œâ”€â”€ llm_integration.py
â”‚   â”‚   â””â”€â”€ model_adapters.py
â”‚   â”œâ”€â”€ gui/               # User interface
â”‚   â”‚   â”œâ”€â”€ main_window.py
â”‚   â”‚   â”œâ”€â”€ field_widgets.py
â”‚   â”‚   â””â”€â”€ snippet_widgets.py
â”‚   â”œâ”€â”€ utils/             # Utilities
â”‚   â”‚   â”œâ”€â”€ snippet_manager.py
â”‚   â”‚   â””â”€â”€ theme_manager.py
â”‚   â””â”€â”€ cli/               # Command line interface
â””â”€â”€ data/                  # Application data
    â””â”€â”€ snippets/          # Default snippet files
```

## âš™ï¸ Configuration

### **User Data Directory**
The application creates a user data directory to store:
- **Snippets**: Custom snippet files
- **Templates**: Saved prompt templates
- **Prompts**: Generated prompts
- **Preferences**: Application settings
- **Debug**: Debug logs (when enabled)

**Location:**
- Windows: `%APPDATA%\FlipFlopPrompt\`
- macOS: `~/Library/Application Support/FlipFlopPrompt/`
- Linux: `~/.config/FlipFlopPrompt/`

### **Content Ratings**
- **PG**: Family-friendly content
- **NSFW**: Adult content (non-explicit)
- **Hentai**: Explicit adult content
- **Custom**: User-defined ratings

### **LLM Models**
The application supports various Ollama models:
- **deepseek-coder:6.7b**: Recommended for prompt refinement
- **gemma:2b**: Lightweight option (PG content only)
- **llama2:7b**: General purpose

## ğŸ”§ Development

### **Running in Development Mode**
```bash
# Activate virtual environment
source .venv/bin/activate

# Run with debug mode
python main.py --gui
```

### **Debug Mode**
Enable debug mode in the Debug menu to:
- Generate detailed logs
- Save LLM input/output
- Track prompt generation steps
- Debug files saved to user data directory

### **Adding Snippets**
1. Create JSON files in the user snippets directory
2. Follow the snippet format (see existing files)
3. Use the "Reload Snippets" menu option
4. Snippets are automatically categorized by field and rating

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

### **Development Guidelines**
- Follow PEP 8 style guidelines
- Add docstrings to new functions
- Update TODO.md with new tasks
- Test on multiple platforms
- Update documentation as needed

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with Python and Tkinter
- LLM integration powered by Ollama
- Inspired by the need for better AI prompt tools
- Community feedback and contributions

## ğŸ“ Support

- **Issues**: Use GitHub Issues for bug reports
- **Discussions**: Use GitHub Discussions for questions
- **Wiki**: Check the wiki for detailed documentation

---

**Version**: 1.0.0  
**Last Updated**: August 2025  
**Status**: Active Development
